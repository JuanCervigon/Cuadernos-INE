{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detección de la multicolinealidad en análisis de regresión.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Tratamiento de la multicolinealidad en una regresión**"
      ],
      "metadata": {
        "id": "1w1-JW1uLyh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La **multicolinealidad** en el análisis de regresión ocurre cuando dos o más variables predictoras están altamente correlacionadas entre sí, de modo que no brindan información única o independiente en el modelo de regresión.\\\n",
        "Para saber si existe multicolinealidad perfecta es suficiente con calcular el determinante de la matriz $(X^tX)$ y ver si es igual a cero. Esto no ocurre si queremos detectar la multicolinealidad aproximada(que las variables no sean linealmente independientes) o no perfecta.\\\n",
        "El **objetivo** es determinar si el grado de multicolinealidad tiene consecuencias negativas sobre nuestro análisis.\\\n",
        "En este esquema utilizaremos dos herramientas básicas para detectar la presencia de multicolinealidad o no.\n",
        "\n",
        "*   Factor de Inflación de la Varianza.\n",
        "*   Número de Condición(NC)\n",
        "\n"
      ],
      "metadata": {
        "id": "jAvsPGDYL6ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcularlas, utilizaremos las librerías numpy, pandas y statsmodels."
      ],
      "metadata": {
        "id": "sIfAzTM2YwI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Factor de Inflación de la Varianza (VIF)**"
      ],
      "metadata": {
        "id": "dj3-3GGr2Kv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Si el grado de correlación entre variables es lo suficientemente alto, puede causar problemas al ajustar e interpretar el modelo de regresión .\n",
        "\n",
        "La forma más común de detectar la multicolinealidad es utilizando el **factor de inflación de la varianza (VIF)**, que mide la correlación y la fuerza de la correlación entre las variables predictoras en un modelo de regresión.\n",
        "\n",
        "\n",
        "*   $VIF=\\frac{Var(\\hat{B}_j)}{Var(\\hat{B}_{jo})}= \\frac{1}{(1-R^2_j)}\n",
        "$\n",
        "\n",
        "\n",
        "*   $Tolerancia=1-R^2_j$\n",
        "\n",
        "donde $Var(\\hat{B}_{jo})$ representa la varianza de la variable explicativa en el caso hipotético de que fuera ortogonal con el resto de variables explicativas(modelo ideal), en cuyo caso $R^2_{jo}=0$ (para que no haya multicolinealidad).\n",
        "\n",
        "\n",
        "\n",
        "El valor de VIF comienza en 1 y no tiene límite superior. Una regla general para interpretar los VIF es la siguiente:\n",
        "\n",
        "\n",
        "*   Un valor de 1 indica que no hay correlación entre una variable predictora dada y cualquier otra variable predictora en el modelo.\n",
        "*   Un valor entre 1 y 4 indica una correlación moderada entre una variable predictora dada y otras variables predictoras en el modelo, pero esto a menudo no es lo suficientemente grave como para requerir atención.\n",
        "\n",
        "*   Un valor mayor que 4 indica  que el grado de multicolinealidad presente en el modelo es preocupante. En este caso, las estimaciones de los coeficientes y los valores p en el resultado de la regresión probablemente no sean confiables.\n",
        "\n",
        "Si $R^2_{j}$ es alto, $Var(\\hat{B}_j)$ será alta. Entonces, $t_{exp}$ será baja, por lo que no rechazaríamos $H_0$, es aquí donde está el problema de multicolinealidad.\n",
        "\n",
        "Finalmente, destacar que existe una aparente contradicción que se sustenta en que el VIF no detecta la relación de la constante con el resto de variables independientes mientras que el número de condición(NC) sí lo hace.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cWA6FH264gR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Ejemplo*"
      ],
      "metadata": {
        "id": "n1deipD93fSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X_train = pd.DataFrame(np.random.standard_normal((20,15)), columns=[f\"x{i}\" for i\n",
        "in range(15)])\n",
        "vif=pd.DataFrame()\n",
        "vif['VIF']=[variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
        "vif['Predictors']=X_train.columns\n",
        "\n",
        "print(vif)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTIvuUHO1amK",
        "outputId": "d77cf8d7-5074-46d6-e4bc-6bd8ddb62298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          VIF Predictors\n",
            "0    2.616103         x0\n",
            "1    3.126974         x1\n",
            "2    6.182713         x2\n",
            "3    5.442437         x3\n",
            "4    3.879028         x4\n",
            "5    1.977315         x5\n",
            "6    4.341102         x6\n",
            "7   10.350489         x7\n",
            "8    6.552275         x8\n",
            "9   13.269630         x9\n",
            "10   3.249546        x10\n",
            "11  25.759691        x11\n",
            "12   4.022593        x12\n",
            "13  16.012262        x13\n",
            "14   3.370031        x14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquellas variables con VIF mayor a 4 serán consideradas con multicolinealidad grave."
      ],
      "metadata": {
        "id": "xTZ2wRVO3mr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Número de Condición (NC)**"
      ],
      "metadata": {
        "id": "vj3NVtyJ6Q8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El **número de condición (NC)** detecta la multicolinealidad no esencial(debida a la relación de la constante con el resto de variables independientes) y esencial(debida a la relación entre las variables independientes excluida la constante).\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "uEfbxWTMBpkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El **NC** se define como: $K(X)= \\sqrt(\\frac{\\xi_(max)}{\\xi_(min})$\\\n",
        "Donde $\\xi_(max)$ y $\\xi_(min)$ son los autovalores máximo y mínimo de la matriz $(X^tX)$. Para Belsley, valores de K(X) entre 20 y 30 supone una multicolinealidad moderada y valores mayores a 30 una multicolinealidad grave."
      ],
      "metadata": {
        "id": "lYqT72HuENsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función **(linalg.cond (x, p=None)** es capaz de devolver el número de condición usando **una** de las siete normas diferentes, dependiendo del valor de p.\n",
        "\\\n",
        "El número de condición de la forma en la que está hecho en este ejemplo es por la Norma de Frobenius(Fro). Esta norma se define como la raíz cuadrada de la suma de los cuadrados de los elementos de la matriz.(L2-norm).\n",
        "\n",
        "$|x|=\\sqrt(\\sum_{k=1}^n|x_k|^2)$"
      ],
      "metadata": {
        "id": "ViDfOld2G55G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Ejemplo*"
      ],
      "metadata": {
        "id": "a2T5JlXMLpV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import linalg as NC\n",
        "x = np.array([[-1, 0, 1], [2, 1, 7], [1, 5, 3]])\n",
        "\n",
        "NC.cond(x)\n",
        "\n",
        "NC.cond(x, 'fro')\n",
        "\n",
        "NC.cond(x, np.inf)\n",
        "\n",
        "NC.cond(x, -np.inf)\n",
        "\n",
        "NC.cond(x, 1)\n",
        "\n",
        "NC.cond(x, -1)\n",
        "\n",
        "NC.cond(x, 2)\n",
        "\n",
        "NC.cond(x, -2)\n",
        "\n",
        "min(NC.svd(x, compute_uv=False))*min(NC.svd(LA.inv(a), compute_uv=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF5FFz40BWdc",
        "outputId": "ba9fff52-a28e-4ca2-ffae-32a3cec967c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8659889084589589"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo, nuestro número de condición (NC) es de 0,86, por lo que nuestro modelo no tendría una multicolinealidad significativa. Tenemos que recordad que para que existiera una multicolinealidad grave debería de ser mayor a 30."
      ],
      "metadata": {
        "id": "i7pqNqPTLH8M"
      }
    }
  ]
}